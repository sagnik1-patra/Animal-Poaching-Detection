{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabf3dc0-5d5f-456b-b427-9f08e6aeb0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {'Gun': 0, 'Human_with_gun': 1, 'Peacock': 2, 'antelope': 3, 'badger': 4, 'bear': 5, 'bison': 6, 'boar': 7, 'chimpanzee': 8, 'coyote': 9, 'deer': 10, 'elephant': 11, 'flamingo': 12, 'fox': 13, 'goose': 14, 'gorilla': 15, 'hedgehog': 16, 'hippopotamus': 17, 'hornbill': 18, 'human': 19, 'hyena': 20, 'kangaroo': 21, 'koala': 22, 'leopard': 23, 'lion': 24, 'okapi': 25, 'orangutan': 26, 'otter': 27, 'ox': 28, 'panda': 29, 'penguin': 30, 'porcupine': 31, 'raccoon': 32, 'reindeer': 33, 'rhinoceros': 34, 'sandpiper': 35, 'seal': 36, 'swan': 37, 'tiger': 38, 'turtle': 39, 'wolf': 40, 'wombat': 41, 'zebra': 42}\n",
      "Processing dataset with image resizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 43/43 [01:52<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples collected: 2463\n",
      "Max boxes in one image: 15\n",
      "HDF5 dataset saved to C:\\Users\\sagni\\Downloads\\Aminal Poching Detection\\animal_poaching_data.h5\n",
      "Metadata saved to C:\\Users\\sagni\\Downloads\\Aminal Poching Detection\\animal_poaching_meta.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_dir = r\"C:\\Users\\sagni\\Downloads\\archive (1)\\archive\\animals\\animals\"\n",
    "save_dir = r\"C:\\Users\\sagni\\Downloads\\Aminal Poching Detection\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "class_to_id = {}\n",
    "id_to_class = {}\n",
    "for idx, class_name in enumerate(sorted(os.listdir(dataset_dir))):\n",
    "    if os.path.isdir(os.path.join(dataset_dir, class_name)):\n",
    "        class_to_id[class_name] = idx\n",
    "        id_to_class[idx] = class_name\n",
    "\n",
    "print(\"Class mapping:\", class_to_id)\n",
    "\n",
    "def parse_yolo_annotation(ann_path, img_width, img_height):\n",
    "    bboxes = []\n",
    "    labels = []\n",
    "    if not os.path.exists(ann_path):\n",
    "        return bboxes, labels\n",
    "    with open(ann_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            cls_id, x_center, y_center, w, h = parts\n",
    "            cls_id = int(cls_id)\n",
    "            x_center = float(x_center)\n",
    "            y_center = float(y_center)\n",
    "            w = float(w)\n",
    "            h = float(h)\n",
    "            xmin = int((x_center - w / 2) * img_width)\n",
    "            ymin = int((y_center - h / 2) * img_height)\n",
    "            xmax = int((x_center + w / 2) * img_width)\n",
    "            ymax = int((y_center + h / 2) * img_height)\n",
    "            xmin = max(0, xmin)\n",
    "            ymin = max(0, ymin)\n",
    "            xmax = min(img_width - 1, xmax)\n",
    "            ymax = min(img_height - 1, ymax)\n",
    "            bboxes.append([xmin, ymin, xmax, ymax])\n",
    "            labels.append(cls_id)\n",
    "    return bboxes, labels\n",
    "\n",
    "print(\"Processing dataset with image resizing...\")\n",
    "\n",
    "target_size = (480, 360)  # width, height\n",
    "\n",
    "data = []\n",
    "\n",
    "for class_name in tqdm(sorted(os.listdir(dataset_dir))):\n",
    "    class_folder = os.path.join(dataset_dir, class_name)\n",
    "    if not os.path.isdir(class_folder):\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(class_folder):\n",
    "        if file.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(class_folder, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load image {img_path}\")\n",
    "                continue\n",
    "\n",
    "            img = cv2.resize(img, target_size)\n",
    "            h, w = target_size[1], target_size[0]\n",
    "\n",
    "            ann_file = os.path.splitext(file)[0] + \".xml.txt\"\n",
    "            ann_path = os.path.join(class_folder, ann_file)\n",
    "\n",
    "            bboxes, labels = parse_yolo_annotation(ann_path, w, h)\n",
    "\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            data.append({\n",
    "                'image': img_rgb,\n",
    "                'bboxes': np.array(bboxes).reshape(-1, 4),\n",
    "                'labels': np.array(labels).reshape(-1),\n",
    "            })\n",
    "\n",
    "print(f\"Total samples collected: {len(data)}\")\n",
    "\n",
    "max_boxes = max(len(d['bboxes']) for d in data) if data else 0\n",
    "print(f\"Max boxes in one image: {max_boxes}\")\n",
    "\n",
    "num_samples = len(data)\n",
    "img_h, img_w, img_c = data[0]['image'].shape\n",
    "\n",
    "images_np = np.zeros((num_samples, img_h, img_w, img_c), dtype=np.uint8)\n",
    "bboxes_np = np.zeros((num_samples, max_boxes, 4), dtype=np.int32)\n",
    "labels_np = np.zeros((num_samples, max_boxes), dtype=np.int32)\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    images_np[i] = d['image']\n",
    "    # Only assign if there are boxes\n",
    "    if d['bboxes'].shape[0] > 0:\n",
    "        bboxes_np[i, :d['bboxes'].shape[0]] = d['bboxes']\n",
    "    if d['labels'].shape[0] > 0:\n",
    "        labels_np[i, :d['labels'].shape[0]] = d['labels']\n",
    "\n",
    "h5_path = os.path.join(save_dir, \"animal_poaching_data.h5\")\n",
    "with h5py.File(h5_path, \"w\") as f:\n",
    "    f.create_dataset(\"images\", data=images_np, compression=\"gzip\")\n",
    "    f.create_dataset(\"bboxes\", data=bboxes_np, compression=\"gzip\")\n",
    "    f.create_dataset(\"labels\", data=labels_np, compression=\"gzip\")\n",
    "\n",
    "print(f\"HDF5 dataset saved to {h5_path}\")\n",
    "\n",
    "pkl_path = os.path.join(save_dir, \"animal_poaching_meta.pkl\")\n",
    "with open(pkl_path, \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"class_to_id\": class_to_id,\n",
    "        \"id_to_class\": id_to_class,\n",
    "        \"max_boxes\": max_boxes,\n",
    "        \"num_samples\": num_samples,\n",
    "        \"image_shape\": (img_h, img_w, img_c),\n",
    "    }, f)\n",
    "print(f\"Metadata saved to {pkl_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8af579-fe0d-45f4-91a5-b6244a341140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
