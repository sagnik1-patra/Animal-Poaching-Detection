{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad51c557-6788-4f34-98b1-dc8db4e9d106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoder saved at: C:\\Users\\sagni\\Downloads\\Aminal Poching Detection\\label_encoder.pkl\n",
      "Epoch 1/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 108ms/step - accuracy: 0.9824 - loss: 0.1626\n",
      "Epoch 2/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0306\n",
      "Epoch 3/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 4/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 5/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 9.5789e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: C:\\Users\\sagni\\Downloads\\Aminal Poching Detection\\poaching_detection_model.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Paths\n",
    "data_dir = r\"C:\\Users\\sagni\\Downloads\\archive (1)\\archive\\animals\\animals\\Human_with_gun\"\n",
    "save_dir = r\"C:\\Users\\sagni\\Downloads\\Aminal Poching Detection\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "img_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "# Load dataset\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for img_name in os.listdir(data_dir):\n",
    "    img_path = os.path.join(data_dir, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img / 255.0\n",
    "    images.append(img)\n",
    "    labels.append(\"Human_with_gun\")  # All images are Human_with_gun\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode labels (binary: poaching or not)\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Save label encoder\n",
    "label_encoder_path = os.path.join(save_dir, \"label_encoder.pkl\")\n",
    "with open(label_encoder_path, \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "print(f\"Label encoder saved at: {label_encoder_path}\")\n",
    "\n",
    "# Model\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, pooling=\"avg\", input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train\n",
    "model.fit(images, labels_encoded, epochs=5, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(save_dir, \"poaching_detection_model.h5\")\n",
    "model.save(model_path)\n",
    "print(f\"Model saved at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be203ba5-fd0d-49e6-984d-e3d6183e4f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
